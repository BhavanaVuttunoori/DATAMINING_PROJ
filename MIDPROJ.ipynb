{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "88b95cca-25ab-496e-a105-f688e962d6a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  imports and configuration\n",
    "import os, sys, time, itertools\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "\n",
    "# BASE_PATH: update if different in your environment (use WSL path if using WSL)\n",
    "BASE_PATH = r\"C:\\Users\\vuttunoori bhavana\\Desktop\\datamining midproj bv269\"\n",
    "\n",
    "DATASETS = {\n",
    "    \"1\": (\"grocery\", \"grocerytransactions.xlsx\"),\n",
    "    \"2\": (\"shopping\", \"shoppingtransactions.xlsx\"),\n",
    "    \"3\": (\"cafe\", \"cafetransactions.xlsx\"),\n",
    "    \"4\": (\"restaurant\", \"restauranttransactions.xlsx\"),\n",
    "    \"5\": (\"bookstore\", \"bookstoretransactions.xlsx\")\n",
    "}\n",
    "\n",
    "ITEM_COLUMNS = [f\"Item{i}\" for i in range(1, 8)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "91e032fc-93a3-494d-80de-d71ffeff2089",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper functions\n",
    "def validate_base_path(path):\n",
    "    if not os.path.isdir(path):\n",
    "        raise FileNotFoundError(f\"Base path not found: {path}\")\n",
    "\n",
    "def list_datasets():\n",
    "    print(\"Available datasets:\")\n",
    "    for key, (short, fname) in DATASETS.items():\n",
    "        print(f\"  {key}. {short} -> {fname}\")\n",
    "\n",
    "def load_transactions_excel(fullpath, sheet_name=0):\n",
    "    df = pd.read_excel(fullpath, sheet_name=sheet_name, dtype=str)\n",
    "    cols = [c for c in ITEM_COLUMNS if c in df.columns]\n",
    "    if not cols:\n",
    "        raise ValueError(f\"Excel {fullpath} does not contain expected columns {ITEM_COLUMNS}.\")\n",
    "    df = df[cols].fillna(\"\").astype(str)\n",
    "    for c in cols:\n",
    "        df[c] = df[c].map(lambda x: x.strip())\n",
    "    transactions = []\n",
    "    for _, row in df.iterrows():\n",
    "        items = [it for it in row.tolist() if it and it.lower() not in (\"nan\",\"none\")]\n",
    "        transactions.append(sorted(set(items)))\n",
    "    return transactions\n",
    "\n",
    "def prepare_onehot_df(transactions):\n",
    "    all_items = sorted({it for t in transactions for it in t})\n",
    "    rows = []\n",
    "    for t in transactions:\n",
    "        rows.append({item: (item in t) for item in all_items})\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "def save_itemsets_rules_excel(basepath, dataset_shortname, approach, freq_dict, n, rules):\n",
    "    os.makedirs(basepath, exist_ok=True)\n",
    "    fi_rows = []\n",
    "    for it, cnt in sorted(freq_dict.items(), key=lambda x: (-x[1], x[0])):\n",
    "        fi_rows.append({\"itemset\": \"|\".join(it), \"count\": cnt, \"support\": cnt / n})\n",
    "    fi_df = pd.DataFrame(fi_rows)\n",
    "    fi_path = os.path.join(basepath, f\"{dataset_shortname}_{approach}_frequent_itemsets.xlsx\")\n",
    "    fi_df.to_excel(fi_path, index=False)\n",
    "\n",
    "    rules_rows = []\n",
    "    for ant, cons, sup, conf in rules:\n",
    "        rules_rows.append({\"antecedent\": \"|\".join(ant), \"consequent\": \"|\".join(cons),\n",
    "                           \"support\": sup, \"confidence\": conf})\n",
    "    rules_df = pd.DataFrame(rules_rows)\n",
    "    rules_path = os.path.join(basepath, f\"{dataset_shortname}_{approach}_rules.xlsx\")\n",
    "    rules_df.to_excel(rules_path, index=False)\n",
    "    return fi_path, rules_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "34cd5a93-bb10-4a69-ab3e-b2229c5be9a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# brute-force algorithm\n",
    "def brute_force_frequent_itemsets(transactions, min_support):\n",
    "    n = len(transactions)\n",
    "    min_count = max(1, int(min_support * n))\n",
    "    items = sorted({it for t in transactions for it in t})\n",
    "    freq = {}\n",
    "    k = 1\n",
    "    while True:\n",
    "        found = False\n",
    "        for comb in itertools.combinations(items, k):\n",
    "            count = sum(1 for t in transactions if set(comb).issubset(t))\n",
    "            if count >= min_count:\n",
    "                freq[tuple(comb)] = count\n",
    "                found = True\n",
    "        if not found:\n",
    "            break\n",
    "        k += 1\n",
    "        if k > len(items):\n",
    "            break\n",
    "    return freq, n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4a77a57d-5dd3-4d5d-b2df-1bd2d2f5491d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wrappers for mlxtend-based Apriori and FP-Growth\n",
    "def run_mlxtend_apriori(transactions, min_support, min_confidence):\n",
    "    try:\n",
    "        from mlxtend.frequent_patterns import apriori, association_rules\n",
    "    except Exception as e:\n",
    "        raise ImportError(\"mlxtend not available. Install in your environment (see message below).\") from e\n",
    "    df = prepare_onehot_df(transactions)\n",
    "    freq = apriori(df, min_support=min_support, use_colnames=True)\n",
    "    n = len(transactions)\n",
    "    if freq.empty:\n",
    "        return {}, n, []\n",
    "    freq_dict = {tuple(sorted(list(s))): int(round(support * n)) for s, support in zip(freq['itemsets'], freq['support'])}\n",
    "    rules_df = association_rules(freq, metric=\"confidence\", min_threshold=min_confidence)\n",
    "    rules = []\n",
    "    for _, row in rules_df.iterrows():\n",
    "        antecedent = tuple(sorted(list(row['antecedents'])))\n",
    "        consequent = tuple(sorted(list(row['consequents'])))\n",
    "        rules.append((antecedent, consequent, float(row['support']), float(row['confidence'])))\n",
    "    return freq_dict, n, rules\n",
    "\n",
    "def run_mlxtend_fpgrowth(transactions, min_support, min_confidence):\n",
    "    try:\n",
    "        from mlxtend.frequent_patterns import fpgrowth, association_rules\n",
    "    except Exception as e:\n",
    "        raise ImportError(\"mlxtend not available. Install in your environment (see message below).\") from e\n",
    "    df = prepare_onehot_df(transactions)\n",
    "    freq = fpgrowth(df, min_support=min_support, use_colnames=True)\n",
    "    n = len(transactions)\n",
    "    if freq.empty:\n",
    "        return {}, n, []\n",
    "    freq_dict = {tuple(sorted(list(s))): int(round(support * n)) for s, support in zip(freq['itemsets'], freq['support'])}\n",
    "    rules_df = association_rules(freq, metric=\"confidence\", min_threshold=min_confidence)\n",
    "    rules = []\n",
    "    for _, row in rules_df.iterrows():\n",
    "        antecedent = tuple(sorted(list(row['antecedents'])))\n",
    "        consequent = tuple(sorted(list(row['consequents'])))\n",
    "        rules.append((antecedent, consequent, float(row['support']), float(row['confidence'])))\n",
    "    return freq_dict, n, rules\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fdb69596-195b-40de-9ab8-083c674127d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  analyzer (auto-skip library-based algorithms when missing)\n",
    "def analyze_dataset_notebook(basepath, filename, shortname,\n",
    "                             min_support=0.2, min_confidence=0.6,\n",
    "                             run_brute=True, run_apriori=True, run_fpgrowth=True):\n",
    "    fullpath = os.path.join(basepath, filename)\n",
    "    if not os.path.isfile(fullpath):\n",
    "        raise FileNotFoundError(f\"Dataset not found: {fullpath}\")\n",
    "    print(f\"\\nLoading dataset: {fullpath}\")\n",
    "    transactions = load_transactions_excel(fullpath)\n",
    "    print(f\"Loaded {len(transactions)} transactions. (first 3): {transactions[:3]}\")\n",
    "    results = {}\n",
    "\n",
    "    if run_brute:\n",
    "        t0 = time.time()\n",
    "        brute_fi, n = brute_force_frequent_itemsets(transactions, min_support)\n",
    "        t_brute = time.time() - t0\n",
    "        print(f\"[Brute] Found {len(brute_fi)} frequent itemsets in {t_brute:.3f}s\")\n",
    "        brute_rules = []\n",
    "        supports = {it: cnt / n for it, cnt in brute_fi.items()}\n",
    "        for it, cnt in brute_fi.items():\n",
    "            if len(it) < 2:\n",
    "                continue\n",
    "            for r in range(1, len(it)):\n",
    "                for ant in itertools.combinations(it, r):\n",
    "                    ant = tuple(sorted(ant))\n",
    "                    cons = tuple(sorted(set(it) - set(ant)))\n",
    "                    ant_sup = supports.get(ant, 0)\n",
    "                    if ant_sup > 0:\n",
    "                        conf = supports[it] / ant_sup\n",
    "                        if conf >= min_confidence:\n",
    "                            brute_rules.append((ant, cons, supports[it], conf))\n",
    "        fi_path, rules_path = save_itemsets_rules_excel(basepath, shortname, \"brute\", brute_fi, n, brute_rules)\n",
    "        print(f\"[Brute] Saved files:\\n  {fi_path}\\n  {rules_path}\")\n",
    "        results['brute'] = {\"itemsets\": brute_fi, \"rules\": brute_rules, \"time\": t_brute}\n",
    "\n",
    "    # Apriori\n",
    "    if run_apriori:\n",
    "        try:\n",
    "            t0 = time.time()\n",
    "            apriori_fi, n_ap, apriori_rules = run_mlxtend_apriori(transactions, min_support, min_confidence)\n",
    "            t_ap = time.time() - t0\n",
    "            print(f\"[Apriori] Found {len(apriori_fi)} frequent itemsets in {t_ap:.3f}s\")\n",
    "            ap_paths = save_itemsets_rules_excel(basepath, shortname, \"apriori\", apriori_fi, n_ap, apriori_rules)\n",
    "            print(f\"[Apriori] Saved files:\\n  {ap_paths[0]}\\n  {ap_paths[1]}\")\n",
    "            results['apriori'] = {\"itemsets\": apriori_fi, \"rules\": apriori_rules, \"time\": t_ap}\n",
    "        except ImportError as ie:\n",
    "            print(\"Apriori (mlxtend) skipped: mlxtend not installed.\")\n",
    "            print(\"Install mlxtend in your environment, e.g.:\")\n",
    "            print(\"  pip install mlxtend\")\n",
    "            results['apriori'] = {\"error\": \"mlxtend_missing\"}\n",
    "        except Exception as e:\n",
    "            print(\"Apriori (mlxtend) failed:\", e)\n",
    "            results['apriori'] = {\"error\": str(e)}\n",
    "\n",
    "    # FP-Growth\n",
    "    if run_fpgrowth:\n",
    "        try:\n",
    "            t0 = time.time()\n",
    "            fpg_fi, n_fp, fpg_rules = run_mlxtend_fpgrowth(transactions, min_support, min_confidence)\n",
    "            t_fp = time.time() - t0\n",
    "            print(f\"[FP-Growth] Found {len(fpg_fi)} frequent itemsets in {t_fp:.3f}s\")\n",
    "            fpg_paths = save_itemsets_rules_excel(basepath, shortname, \"fpgrowth\", fpg_fi, n_fp, fpg_rules)\n",
    "            print(f\"[FP-Growth] Saved files:\\n  {fpg_paths[0]}\\n  {fpg_paths[1]}\")\n",
    "            results['fpgrowth'] = {\"itemsets\": fpg_fi, \"rules\": fpg_rules, \"time\": t_fp}\n",
    "        except ImportError as ie:\n",
    "            print(\"FP-Growth (mlxtend) skipped: mlxtend not installed.\")\n",
    "            print(\"Install mlxtend in your environment, e.g.:\")\n",
    "            print(\"  pip install mlxtend\")\n",
    "            results['fpgrowth'] = {\"error\": \"mlxtend_missing\"}\n",
    "        except Exception as e:\n",
    "            print(\"FP-Growth (mlxtend) failed:\", e)\n",
    "            results['fpgrowth'] = {\"error\": str(e)}\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bea60c69-59a3-40e9-a673-e3055cd6f054",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available datasets:\n",
      "  1. grocery -> grocerytransactions.xlsx\n",
      "  2. shopping -> shoppingtransactions.xlsx\n",
      "  3. cafe -> cafetransactions.xlsx\n",
      "  4. restaurant -> restauranttransactions.xlsx\n",
      "  5. bookstore -> bookstoretransactions.xlsx\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter dataset number (1-5):  1\n",
      "Enter minimum support (percent or fraction):  79\n",
      "Enter minimum confidence (percent or fraction):  45\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Choose algorithm(s) to run:\n",
      "  1. Brute-force\n",
      "  2. Apriori (mlxtend)\n",
      "  3. FP-Growth (mlxtend)\n",
      "  4. All\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter choice (1-4):  3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading dataset: C:\\Users\\vuttunoori bhavana\\Desktop\\datamining midproj bv269\\grocerytransactions.xlsx\n",
      "Loaded 50 transactions. (first 3): [['Bread', 'Butter', 'Eggs', 'Milk'], ['Apples', 'Bananas', 'Cereal', 'Yogurt'], ['Chicken', 'Lettuce', 'Pasta', 'Rice', 'Tomatoes']]\n",
      "FP-Growth (mlxtend) skipped: mlxtend not installed.\n",
      "Install mlxtend in your environment, e.g.:\n",
      "  pip install mlxtend\n",
      "\n",
      "Done. Results keys: dict_keys(['fpgrowth'])\n"
     ]
    }
   ],
   "source": [
    "#  interactive cell you can run: choose dataset & algorithms\n",
    "list_datasets()\n",
    "choice = input(\"Enter dataset number (1-5): \").strip()\n",
    "if choice not in DATASETS:\n",
    "    raise ValueError(\"Invalid choice\")\n",
    "filename, shortname = DATASETS[choice][1], DATASETS[choice][0]\n",
    "\n",
    "# Support & confidence\n",
    "s = input(\"Enter minimum support (percent or fraction): \").strip()\n",
    "c = input(\"Enter minimum confidence (percent or fraction): \").strip()\n",
    "s = float(s)/100.0 if float(s) > 1 else float(s)\n",
    "c = float(c)/100.0 if float(c) > 1 else float(c)\n",
    "\n",
    "print(\"\\nChoose algorithm(s) to run:\")\n",
    "print(\"  1. Brute-force\")\n",
    "print(\"  2. Apriori (mlxtend)\")\n",
    "print(\"  3. FP-Growth (mlxtend)\")\n",
    "print(\"  4. All\")\n",
    "algo_choice = input(\"Enter choice (1-4): \").strip()\n",
    "if algo_choice not in (\"1\",\"2\",\"3\",\"4\"):\n",
    "    algo_choice = \"4\"\n",
    "run_brute = algo_choice in (\"1\",\"4\")\n",
    "run_apriori = algo_choice in (\"2\",\"4\")\n",
    "run_fpgrowth = algo_choice in (\"3\",\"4\")\n",
    "\n",
    "results = analyze_dataset_notebook(BASE_PATH, filename, shortname,\n",
    "                                  min_support=s, min_confidence=c,\n",
    "                                  run_brute=run_brute, run_apriori=run_apriori, run_fpgrowth=run_fpgrowth)\n",
    "\n",
    "print(\"\\nDone. Results keys:\", results.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f842293-bef8-440a-b623-87f555944c38",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
